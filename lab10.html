<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8" />
        <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no" />
        <meta name="description" content="" />
        <meta name="author" content="" />
        <title>Lab 10</title>
        <link rel="icon" type="image/x-icon" href="assets/favicon.ico" />
        <!-- Font Awesome icons (free version)-->
        <script src="https://use.fontawesome.com/releases/v6.1.0/js/all.js" crossorigin="anonymous"></script>
        <!-- Google fonts-->
        <link href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic" rel="stylesheet" type="text/css2" />
        <link href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800" rel="stylesheet" type="text/css2" />
        <!-- Core theme CSS (includes Bootstrap)-->
        <link href="css2/styles.css" rel="stylesheet" />
    </head>
    <body>
        <!-- Page Header-->
        <header class="masthead" style="background-image: url('assets/img/lab4.jpg')">
            <div class="container position-relative px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <div class="site-heading">
                            <h1>Lab 10: Localization (SIM) </h1>
                            <h2>This lab implements gril localization in the simulation robot using Bayes Filter.</h2>
                        </div>
                    </div>
                </div>
            </div>
        </header>
        <!-- Post Content-->
        <article class="mb-4">
            <div class="container px-4 px-lg-5">
                <div class="row gx-4 gx-lg-5 justify-content-center">
                    <div class="col-md-10 col-lg-8 col-xl-7">
                        <h2 class="section-heading">Background Information</h2>
                        <p>The Pre-lab portion of the lab consisted of learning the implementation of Bayes Filter in grid localization. The codebase for the simulation was provided in class and I had to implement the code just for the grid localization of the virtual robot.</p>
                        <p>The robot state is given as an array of [x, y, theta], defined as the robot's pose. With this, the purpose of the Bayes Filter is to update the belief in the robot (the probability that the robot is in a certain state) using the sensor values. Thus, the Bayes Filter algorithm allows us to predict the robot's position and update its position that reduces its uncertainty. </p>

                        <h2 class="section-heading">Code Implementation</h2>
                        <p>Shown below is the Bayes Filter algorithm that we are implementing in this lab, where for every position, we predict the location of the robot and update it accordingly. The algorithm is divided up into several helper functions, each explained below: computer_control(), odom_motion_model(), prediction_step(), sensor_model() and update_step().</p>
                        <center><img class="center" src="assets/img/lab10/bayes.png" width = "550"/></center>

                        <p><b>Compute Control</b></p>
                        <p>The first function, <b>compute_control(cur_pose, prev_pose)</b>, takes in two parameters -- current and previous pose and returns the necessary variables for the Bayes Filter algorithm. It returns delta_rot_1, delta_trans, delta_rot_2, which are the two rotation one translation values between the two poses. </p>
                        <center><img class="center" src="assets/img/lab10/def.png" width = "550"/></center>
                        <p>Using trignometry and python math/np, I calculated the angle between the current heading and translation angle (<b>delta_rot_1</b>), the translation distance (<b>delta_trans</b>), and the angle between the translation angle and final heading (<b>delta_rot_2</b>).   </p>
                        <p>Below is the code snippet of this function. </p>
                        <center><img class="center" src="assets/img/lab10/compute_control.png" width = "600"/></center>

                        <p><b>Odometry Motion Model</b></p>
                        <p>Next step is to compute the probability that the robot would end up in the current pose, given a control input and previous pose. We used the gaussian function and multiplied the probability of (rot1, trans, rot2) to get the final odometry motion probability.  </p>
                        <center><img class="center" src="assets/img/lab10/prob.png" width = "550"/></center>
                        <p>The code implementation is as follows. </p>
                        <center><img class="center" src="assets/img/lab10/odom_motion_model.png" width = "650"/></center>

                        <p><b>Prediction Step</b></p>
                        <p>The prediction step utilized the current and previous position of the robot to create the belief_bar in the algorithm. I used <b>six</b> nested for loops: first three for the previous pose and the last three for current pose. The function calculated the probability of getting from the previous position to the current position and multiplied it with the belief in the previous step. After summing that value for each position, it was stored in loc.bel_bar after normalizing the sum. </p>
                        <p>The code implemention is as follows. </p>
                        <center><img class="center" src="assets/img/lab10/belbar.png" width = "650"/></center>

                        <p><b>Sensor Model</b></p>
                        <p>Now that the prediction step is over, it is time to update the robot's position. This step uses the gaussian function once again, like the motion model, but for the sensor output values. It computes the likelihood of getting accurate sensor readings given the robot's pose. With the given sigma value, I looped through the 18 sensor measurements and calculated the probability that the sensor readings are accurate. Then, the 18 probability values are appended to thr prob array and later multiplied all together in update_step().</p>
                        <p>The implemented code is shown below. </p>
                        <center><img class="center" src="assets/img/lab10/sensormodel.png" width = "650"/></center>

                        <p><b>Update Step</b></p>
                        <p>With three nested-loops, I iterated through every possible current poses of the virtual robot and multiplied the intermediate belief (output of the prediction step) with the sensor readings probability from sensor model. Then I updated the belief at each pose with the multiplied value. After the for loops are over, the probability is again normalized and stored in loc.bel.</p>
                        <p>This is the update_step function.</p>
                        <center><img class="center" src="assets/img/lab10/update.png" width = "650"/></center>

                        <h2 class="section-heading">Results</h2>
                        <p>The Bayes filter implementation results are shown below, where green is the true pose and blue is the belief. </p>
                        <center><img class="center" src="assets/img/lab10/final.png" width = "650"/></center>
                        <p></p>

                    </div>
                </div>
            </div>
        </article>
        <!-- Bootstrap core JS-->
        <script src="https://cdn.jsdelivr.net/npm/bootstrap@5.1.3/dist/js/bootstrap.bundle.min.js"></script>
        <!-- Core theme JS-->
        <script src="js/scripts.js"></script>
    </body>
</html>
